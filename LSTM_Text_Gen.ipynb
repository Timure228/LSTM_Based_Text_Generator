{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Timure228/LSTM_Based_Text_Generator/blob/main/LSTM_Text_Gen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM Text Generator"
      ],
      "metadata": {
        "id": "qB-TkSVoTQv9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "nv0VkpkjjKyv"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import RNN, LSTM, Dropout\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "import regex\n",
        "import string\n",
        "\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gi9LRPGeHxAv",
        "outputId": "92c8b31f-ba65-4b0f-901f-97e112087992"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21254"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ],
      "source": [
        "FILE = \"all(2M).txt\"\n",
        "with open(FILE, \"r\") as f:\n",
        "  lines_amount = f.read().count(\"\\n\") + 1\n",
        "\n",
        "lines_amount"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "iE4hVCEJ-Pc9"
      },
      "outputs": [],
      "source": [
        "translator = str.maketrans('', '', string.punctuation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yw2xpXDmFnA6",
        "outputId": "0ba78ea5-d022-4cd7-de93-8d48839ef999"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8470\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "with open(FILE, \"r\") as f:\n",
        "  text = f.read()\n",
        "  text = text.strip().translate(translator).lower()\n",
        "  text = text[:int(len(text)*0.5)]\n",
        "  print(text.count(\"\\n\") + 1)\n",
        "\n",
        "# print(f\"Before: {len(text)}\")\n",
        "\n",
        "# text = re.sub('\\)', '',text)\n",
        "# text = re.sub('\\(', '',text)\n",
        "\n",
        "# for pattern in set(re.findall('<unk>', text)):\n",
        "#   text = re.sub(pattern, '', text)\n",
        "\n",
        "# print(f\"After: {len(text)}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_text = text[:int(len(text)*0.8)]\n",
        "test_text = text[int(len(text)*0.8):]"
      ],
      "metadata": {
        "id": "DIOH1czwPRHg"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ULztpcxPBzL",
        "outputId": "f212ff34-eab1-4155-f568-eb5605199dc1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Â£82bn',\n",
              " 'sprawling',\n",
              " 'bomblarbi',\n",
              " 'gives',\n",
              " 'titled',\n",
              " 'ambitious',\n",
              " 'cans',\n",
              " 'buttons',\n",
              " 'sharapovas',\n",
              " 'harry']"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ],
      "source": [
        "# Tokenize\n",
        "tokens = []\n",
        "for i in text.split():\n",
        "  for j in i.split():\n",
        "    tokens.append(j)\n",
        "\n",
        "tokens = list(set(tokens))\n",
        "vocab_size = len(tokens)\n",
        "tokens[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "collapsed": true,
        "id": "VUFMlZb62Fx8"
      },
      "outputs": [],
      "source": [
        "indx_to_token = {indx: token for indx, token in enumerate(tokens)}\n",
        "token_to_indx = {token: indx for indx, token in enumerate(tokens)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "5RWKrKsPKKum",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Create encode and decode function\n",
        "def encode(arr: list, token_to_indx=token_to_indx):\n",
        "  try:\n",
        "    for i in arr:\n",
        "      for j in range(len(i)):\n",
        "        i[j] = token_to_indx[i[j]]\n",
        "  except KeyError:\n",
        "    print(i)\n",
        "    print(i[j])\n",
        "    i.remove(i[j])\n",
        "  return arr\n",
        "\n",
        "def decode(arr: list, indx_to_token=indx_to_token):\n",
        "  for i in arr:\n",
        "    for j in range(len(i)):\n",
        "      i[j] = indx_to_token[i[j]]\n",
        "  return arr\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LENGTH = 10\n",
        "\n",
        "def create_sequence(X: list, y: list, text: str, SEQ_LENGTH = SEQ_LENGTH, STEP=1):\n",
        "  text_arr = text.split()\n",
        "  for i in range(0, len(text_arr)- SEQ_LENGTH, STEP):\n",
        "    X.append(text_arr[i:i + SEQ_LENGTH])\n",
        "    y.append([text_arr[i+SEQ_LENGTH]])\n",
        "  return X, y"
      ],
      "metadata": {
        "id": "8-avz4eB74mi"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EO2Uc-wBcAxg",
        "outputId": "5bdf236a-2305-46f5-a5a2-9e2954d32cb1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['the',\n",
              "  'war',\n",
              "  'to',\n",
              "  'president',\n",
              "  'chirac',\n",
              "  'asking',\n",
              "  'that',\n",
              "  'october',\n",
              "  '31',\n",
              "  'be'],\n",
              " ['made'])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "# Creating the sequences\n",
        "X_train = []\n",
        "y_train = []\n",
        "\n",
        "X_test = []\n",
        "y_test = []\n",
        "\n",
        "X_train, y_train = create_sequence(X_train, y_train, train_text, SEQ_LENGTH=10)\n",
        "X_test, y_test = create_sequence(X_test, y_test, test_text, SEQ_LENGTH=10)\n",
        "\n",
        "X_test[1], y_test[1]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoding, converting to numerical\n",
        "X_train = encode(X_train)\n",
        "y_train = encode(y_train)"
      ],
      "metadata": {
        "id": "o1qgt-aqxdxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = encode(X_test)\n",
        "y_test = encode(y_test)"
      ],
      "metadata": {
        "id": "-BTNPmTkRG5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h2kRTL4bZttO"
      },
      "outputs": [],
      "source": [
        "# Padding X and y\n",
        "X_train_padded = pad_sequences(X_train, maxlen=10, padding='post', value=0)  # 'post' means pad at the end of each sequence\n",
        "y_train_padded = pad_sequences(y_train, maxlen=10, padding='post', value=0)\n",
        "\n",
        "X_test_padded = pad_sequences(X_test, maxlen=10, padding='post', value=0)\n",
        "y_test_padded = pad_sequences(y_test, maxlen=10, padding='post', value=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1sZUgwKeCi0",
        "outputId": "a8493196-babc-482d-9424-063592655726"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X Shape: (33998, 10) | y shape: (33998, 10)\n"
          ]
        }
      ],
      "source": [
        "print(f\"X Shape: {X_train_padded.shape} | y shape: {y_train_padded.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kAjFFhQl0xGy"
      },
      "outputs": [],
      "source": [
        "# Converting X and y to categorical vectors\n",
        "X_train_cat = to_categorical(X_train_padded, num_classes=vocab_size)\n",
        "y_train_cat = to_categorical(y_train_padded, num_classes=vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_cat = to_categorical(X_test_padded, num_classes=vocab_size)\n",
        "y_test_cat = to_categorical(y_test_padded, num_classes=vocab_size)"
      ],
      "metadata": {
        "id": "asCVgPS_7ukg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_train_cat[133])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0BNaCuNSSrq",
        "outputId": "ba7d4b6f-6edf-4b5a-df57-64c9f3e24d63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_6eD20YK1hxr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c9bd999-d9e3-4646-bd5f-eae40309d346"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X Rank: 3 | y Rank: 3\n",
            "X Shape: (1354, 10, 720) | y shape: (1354, 10, 720)\n",
            "X Type: <class 'numpy.ndarray'> | y Type: <class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "# Check the ranks of X and y\n",
        "print(f\"X Rank: {tf.rank(X_train_cat)} | y Rank: {tf.rank(y_train_cat)}\")\n",
        "print(f\"X Shape: {X_train_cat.shape} | y shape: {y_train_cat.shape}\")\n",
        "print(f\"X Type: {type(X_train_cat)} | y Type: {type(y_train_cat)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8S_U52wuJgNp"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Embedding, Dropout"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TensorFlow Based"
      ],
      "metadata": {
        "id": "Oc-63WvqGWd9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bNnQfMEHgeqy"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(keras.layers.Input(shape=(41, X_train_cat.shape[2])))\n",
        "model.add(Dropout(rate=0.2))\n",
        "model.add(LSTM(128, return_sequences=True))\n",
        "model.add(LSTM(64, return_sequences=True))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(rate=0.5))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g1QcBuvyL_P5"
      },
      "outputs": [],
      "source": [
        "history = model.fit(X_train_cat, y_train_cat, epochs=50, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "HCnJocw41PWy",
        "outputId": "92c03e49-d792-4c24-a606-cda52ebfbeb8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7ac58a705510>]"
            ]
          },
          "metadata": {},
          "execution_count": 77
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Plot the Loss Curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.epoch, history.history[\"loss\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "SvvMdsmP1tQt",
        "outputId": "11a7f443-4dba-40ae-aafe-6df4c6eb3e19"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "ââââââââââââââââââââââââââââââââââââââââ³ââââââââââââââââââââââââââââââ³ââââââââââââââââââ\n",
              "â\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mâ\n",
              "â¡âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ©\n",
              "â dropout (\u001b[38;5;33mDropout\u001b[0m)                    â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m41\u001b[0m, \u001b[38;5;34m1197\u001b[0m)            â               \u001b[38;5;34m0\u001b[0m â\n",
              "ââââââââââââââââââââââââââââââââââââââââ¼ââââââââââââââââââââââââââââââ¼ââââââââââââââââââ¤\n",
              "â lstm (\u001b[38;5;33mLSTM\u001b[0m)                          â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m41\u001b[0m, \u001b[38;5;34m128\u001b[0m)             â         \u001b[38;5;34m678,912\u001b[0m â\n",
              "ââââââââââââââââââââââââââââââââââââââââ¼ââââââââââââââââââââââââââââââ¼ââââââââââââââââââ¤\n",
              "â lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m41\u001b[0m, \u001b[38;5;34m64\u001b[0m)              â          \u001b[38;5;34m49,408\u001b[0m â\n",
              "ââââââââââââââââââââââââââââââââââââââââ¼ââââââââââââââââââââââââââââââ¼ââââââââââââââââââ¤\n",
              "â dense (\u001b[38;5;33mDense\u001b[0m)                        â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m41\u001b[0m, \u001b[38;5;34m64\u001b[0m)              â           \u001b[38;5;34m4,160\u001b[0m â\n",
              "ââââââââââââââââââââââââââââââââââââââââ¼ââââââââââââââââââââââââââââââ¼ââââââââââââââââââ¤\n",
              "â dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m41\u001b[0m, \u001b[38;5;34m64\u001b[0m)              â               \u001b[38;5;34m0\u001b[0m â\n",
              "ââââââââââââââââââââââââââââââââââââââââ¼ââââââââââââââââââââââââââââââ¼ââââââââââââââââââ¤\n",
              "â dense_1 (\u001b[38;5;33mDense\u001b[0m)                      â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m41\u001b[0m, \u001b[38;5;34m1197\u001b[0m)            â          \u001b[38;5;34m77,805\u001b[0m â\n",
              "ââââââââââââââââââââââââââââââââââââââââ´ââââââââââââââââââââââââââââââ´ââââââââââââââââââ\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">ââââââââââââââââââââââââââââââââââââââââ³ââââââââââââââââââââââââââââââ³ââââââââââââââââââ\n",
              "â<span style=\"font-weight: bold\"> Layer (type)                         </span>â<span style=\"font-weight: bold\"> Output Shape                </span>â<span style=\"font-weight: bold\">         Param # </span>â\n",
              "â¡âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ©\n",
              "â dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1197</span>)            â               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â\n",
              "ââââââââââââââââââââââââââââââââââââââââ¼ââââââââââââââââââââââââââââââ¼ââââââââââââââââââ¤\n",
              "â lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             â         <span style=\"color: #00af00; text-decoration-color: #00af00\">678,912</span> â\n",
              "ââââââââââââââââââââââââââââââââââââââââ¼ââââââââââââââââââââââââââââââ¼ââââââââââââââââââ¤\n",
              "â lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              â          <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> â\n",
              "ââââââââââââââââââââââââââââââââââââââââ¼ââââââââââââââââââââââââââââââ¼ââââââââââââââââââ¤\n",
              "â dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              â           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> â\n",
              "ââââââââââââââââââââââââââââââââââââââââ¼ââââââââââââââââââââââââââââââ¼ââââââââââââââââââ¤\n",
              "â dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              â               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â\n",
              "ââââââââââââââââââââââââââââââââââââââââ¼ââââââââââââââââââââââââââââââ¼ââââââââââââââââââ¤\n",
              "â dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1197</span>)            â          <span style=\"color: #00af00; text-decoration-color: #00af00\">77,805</span> â\n",
              "ââââââââââââââââââââââââââââââââââââââââ´ââââââââââââââââââââââââââââââ´ââââââââââââââââââ\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,430,857\u001b[0m (9.27 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,430,857</span> (9.27 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m810,285\u001b[0m (3.09 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">810,285</span> (3.09 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m1,620,572\u001b[0m (6.18 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,620,572</span> (6.18 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Model structure\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "collapsed": true,
        "id": "baUES5EQDfz5",
        "outputId": "4750370c-8abc-47c2-bde1-aa63ab3df393"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'why'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-91-0fcbd60068e3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0minput_string_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0minput_string_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-91-0fcbd60068e3>\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(string)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0minput_string_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtoken_to_indx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_string\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0minput_string_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_string_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pre\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0minput_string_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_string_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-91-0fcbd60068e3>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0minput_string_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtoken_to_indx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_string\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0minput_string_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_string_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pre\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0minput_string_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_string_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'why'"
          ]
        }
      ],
      "source": [
        "input_string = [[\"why\", \"those\", \"people\", \"so\", \"about\"]]\n",
        "\n",
        "def convert(string):\n",
        "  input_string_arr = [token_to_indx[i] for i in input_string[0]]\n",
        "  input_string_arr = pad_sequences(input_string_arr, maxlen=10, padding=\"pre\", value=0)\n",
        "  input_string_arr = tf.keras.utils.to_categorical(input_string_arr, num_classes=vocab_size)\n",
        "  return input_string_arr\n",
        "\n",
        "input_string_arr = convert(input_string)\n",
        "\n",
        "\n",
        "y_preds = model.predict(input_string_arr)\n",
        "labels = tf.argmax(y_preds, axis=2)\n",
        "\n",
        "print([decode(input_string)[0] + [indx_to_token[int(labels[0][i])] for i in range(len(labels)) if int(labels[0][i]) != 0]])\n",
        "labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rkiQ_-V3Rdc",
        "outputId": "865427c4-ec6b-42c7-dce3-1c77b4a0e0ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m25/25\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9047 - loss: 0.7137\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7272857427597046, 0.9033333659172058]"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ],
      "source": [
        "# Evaluating the model\n",
        "model.evaluate(X_test_cat, y_test_cat)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"model_0.keras\")"
      ],
      "metadata": {
        "id": "ESIyc_glQ1Rp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch Based"
      ],
      "metadata": {
        "id": "VzvI6psfGTGh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = []\n",
        "y_train = []\n",
        "\n",
        "X_test = []\n",
        "y_test = []\n",
        "\n",
        "X_train, y_train = create_sequence(X_train, y_train, train_text, SEQ_LENGTH=10)\n",
        "X_test, y_test = create_sequence(X_test, y_test, test_text, SEQ_LENGTH=10)\n",
        "\n",
        "# Encoding, converting to numerical\n",
        "X_train = encode(X_train)\n",
        "y_train = encode(y_train)\n",
        "\n",
        "X_test = encode(X_test)\n",
        "y_test = encode(y_test)"
      ],
      "metadata": {
        "id": "f7CiPmqs6QK0"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = torch.tensor(X_train, dtype=torch.float32).reshape(len(X_train), SEQ_LENGTH) / vocab_size\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
        "\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32).reshape(len(X_test), SEQ_LENGTH) / vocab_size\n",
        "y_test = torch.tensor(y_test, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "YlsjA9lvf8I4"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model0(nn.Module):\n",
        "  def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
        "    super(Model0, self).__init__()\n",
        "    self.layer_dim = layer_dim\n",
        "    self.hidden_dim = hidden_dim\n",
        "\n",
        "    self.lstm = torch.nn.LSTM(input_dim, hidden_dim, layer_dim,\n",
        "                     batch_first=True)\n",
        "    self.linear = torch.nn.Linear(hidden_dim, output_dim)\n",
        "    self.softMax = torch.nn.Softmax()\n",
        "\n",
        "  def forward(self, x, h0=None, c0=None):\n",
        "    if h0 is None and c0 is None:\n",
        "      h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim)\n",
        "      c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim)\n",
        "\n",
        "    out, (hn, hc) = self.lstm(x, (h0, c0))\n",
        "    out = self.linear(out[:, -1, :])\n",
        "    return out, hn, hc"
      ],
      "metadata": {
        "id": "ozMKoCdDS2Tv"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model1(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size):\n",
        "    super().__init__()\n",
        "    self.lstm = nn.LSTM(input_size, hidden_size, num_layers=1, dropout=0.2)\n",
        "    self.linear = nn.Linear(128, out_features=output_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x, _ = self.lstm(x)\n",
        "    x = x[:, -1]\n",
        "    x = self.linear(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "jG6A7d8UhQRl"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = Model1(input_size=SEQ_LENGTH, hidden_size=256, output_size=128)\n",
        "loss_fn = nn.CrossEntropyLoss(reduction=\"sum\")\n",
        "optimizer = torch.optim.Adam(model1.parameters(), lr=0.01)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dlx4lAjrk0c6",
        "outputId": "17dcb284-5a50-45d3-bfdb-190cc1e9ec43"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "\n",
        "train_dataset_loader = data.DataLoader(data.TensorDataset(X_train, y_train), shuffle=True, batch_size=batch_size)\n",
        "test_dataset_loader = data.DataLoader(data.TensorDataset(X_test, y_test), shuffle=False, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "E-sGt90krarg"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://machinelearningmastery.com/text-generation-with-lstm-in-pytorch/"
      ],
      "metadata": {
        "id": "5PUO0PrxtnUb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Training loop for model 1\n",
        "from torch.utils import data\n",
        "\n",
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  model1.train()\n",
        "  for X_train, y_train in train_dataset_loader:\n",
        "    if len(X_train) == 48:\n",
        "      continue\n",
        "\n",
        "    y_pred = model1(X_train)\n",
        "\n",
        "    loss = loss_fn(y_pred, y_train.squeeze(1))\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "  # Validation\n",
        "  model1.eval()\n",
        "  loss = 0\n",
        "  with torch.no_grad():\n",
        "    for X_train, y_train in train_dataset_loader:\n",
        "        if len(X_train) == 48:\n",
        "          continue\n",
        "        y_pred = model1(X_train)\n",
        "        loss += loss_fn(y_pred, y_train.squeeze(1))\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "      print(f\"Epoch: {epoch + 1} | Loss: {loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "WopJN0tQle7j",
        "outputId": "035718bd-f963-4ea5-f02d-6f5cded6eb3f"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 5 | Loss: 8053442560.0000\n",
            "Epoch: 10 | Loss: 8053238272.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "custom_string = \"this thing is based on the new type of the\"\n",
        "X_custom = [[]]\n",
        "\n",
        "for i in custom_string.split():\n",
        "  X_custom[0].append(i)\n",
        "\n",
        "# Encoding, converting to numerical\n",
        "X_custom = encode(X_custom)"
      ],
      "metadata": {
        "id": "FqEgzFgIwEYr"
      },
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_custom = torch.tensor(X_custom, dtype=torch.float32) / vocab_size"
      ],
      "metadata": {
        "id": "_m8vpVzlU2gm"
      },
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1(X_custom)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "_MLstVhTVedg",
        "outputId": "2c606f4e-f4fa-48e3-fc0b-a16b9949792c"
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (1x1 and 128x128)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-170-03f5f9ad2050>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_custom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-84-b7552355fbb7>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x1 and 128x128)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def nuke(n):\n",
        "  a = []\n",
        "  for i in range(10):\n",
        "    if n > 1:\n",
        "      a.append(nuke(n-1))\n",
        "    else:\n",
        "      a.append(i)\n",
        "  return a\n",
        "\n",
        "# print(nuke(10))"
      ],
      "metadata": {
        "id": "L9am0PVGZ5hC"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "authorship_tag": "ABX9TyMpnAxBp4ytmfIKKuSFtc7J",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}